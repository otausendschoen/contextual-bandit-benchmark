# Contextual Bandit Benchmarks

**Final Project - Reinforcement Learning**  
**Authors:** Marvin Ernst, Oliver Tausendschoen & Timothy Cassel  
**Institution:** Barcelona School of Economics  
**Year:** 2025

<p align="center">
  <img src="https://img.shields.io/badge/python-3.12-blue?logo=python">
</p>

---

## Project Overview

This project compares **classical contextual bandits** to **neural contextual bandits**, evaluating the performance differences between traditional and deep learning approaches.

**Algorithms:**
- (0) Random Policy
- (1) LinUCB (Oliver)
- (2) LinTS

---

## Related Work

### Papers (not doing NeuralUCB)

**Neural Contextual Bandits with UCB-based Exploration**  
*Dongruo Zhou, Lihong Li, Quanquan Gu*  
https://arxiv.org/abs/1911.04462

Proposes NeuralUCB, using deep neural networks for contextual bandits with near-optimal regret guarantee.

**Neural Thompson Sampling**  
*Weitong Zhang, Dongruo Zhou, Lihong Li, Quanquan Gu*  
https://arxiv.org/pdf/2010.00827

Proposes NeuralTS, using deep neural networks for both exploration and exploitation also with near-optimal regret guarantee. 

### Git Repos
https://github.com/wadx2019/Neural-Bandit

https://github.com/sauxpa/neural_exploration

### Dataset
[Open Bandit Pipeline](https://github.com/st-tech/zr-obp) by Zozo Research
